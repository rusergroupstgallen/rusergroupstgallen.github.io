<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Intro-to-Tidymodels.knit</title>
    <meta charset="utf-8" />
    <script src="libs/header-attrs/header-attrs.js"></script>
    <link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">


class: center, middle



&lt;style type="text/css"&gt;
pre {
  background: #F8F8F8;
  max-width: 100%;
  overflow-x: scroll;
}
&lt;/style&gt;

&lt;style type="text/css"&gt;
.center2 {
  margin: 0;
  position: absolute;
  top: 50%;
  left: 50%;
  -ms-transform: translate(-50%, -50%);
  transform: translate(-50%, -50%);
}
&lt;/style&gt;

&lt;style type="text/css"&gt;
.scroll-output {
  height: 80%;
  overflow-y: scroll;
}
&lt;/style&gt;



# Introduction to Tidymodels

## by

&lt;img src="GraphicsSlides/Logo RUG hell.png" width="50%" /&gt;

##### Author/Presenter: Mathias Steilen
##### Last updated: _2022-08-26 00:20:46_

---

# Tidymodels

&lt;br&gt;

.center[
&lt;img src="GraphicsSlides/tidymodels.png" width="100%" /&gt;

_[(Source)](https://www.tidymodels.org/)_
]

---

# Goals for this session

- Know how to model with `tidymodels` by working live on a data set
- Be able to use that knowledge and the code to apply it to other data and with other models

&lt;br&gt;

.center[
&lt;img src="GraphicsSlides/to do.png" width="50%" /&gt;
]

---

# Today's data set

.center[
&lt;img src="GraphicsSlides/pumpkin.jpg" width="50%" /&gt;
]

&gt; The Great Pumpkin Commonwealth's (GPC) mission cultivates the hobby of growing giant pumpkins throughout the world by establishing standards and regulations that ensure quality of fruit, fairness of competition, recognition of achievement, fellowship and education for all participating growers and weigh-off sites. ([TidyTuesday Link](https://github.com/rfordatascience/tidytuesday/blob/master/data/2021/2021-10-19/readme.md))

---

# Off we go


```r
pumpkins &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-10-19/pumpkins.csv')
```

```
## Rows: 28065 Columns: 14
## ── Column specification ────────────────────────────────────────────────────────
## Delimiter: ","
## chr (14): id, place, weight_lbs, grower_name, city, state_prov, country, gpc...
## 
## ℹ Use `spec()` to retrieve the full column specification for this data.
## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.
```


```r
library(tidyverse)
library(tidymodels)
library(doParallel)
library(vip)
```


---

### Inspecting the data


```r
glimpse(pumpkins)
```

```
## Rows: 28,065
## Columns: 14
## $ id                &lt;chr&gt; "2013-F", "2013-F", "2013-F", "2013-F", "2013-F", "2…
## $ place             &lt;chr&gt; "1", "2", "3", "4", "5", "5", "7", "8", "9", "10", "…
## $ weight_lbs        &lt;chr&gt; "154.50", "146.50", "145.00", "140.80", "139.00", "1…
## $ grower_name       &lt;chr&gt; "Ellenbecker, Todd &amp; Sequoia", "Razo, Steve", "Ellen…
## $ city              &lt;chr&gt; "Gleason", "New Middletown", "Glenson", "Combined Lo…
## $ state_prov        &lt;chr&gt; "Wisconsin", "Ohio", "Wisconsin", "Wisconsin", "Wisc…
## $ country           &lt;chr&gt; "United States", "United States", "United States", "…
## $ gpc_site          &lt;chr&gt; "Nekoosa Giant Pumpkin Fest", "Ohio Valley Giant Pum…
## $ seed_mother       &lt;chr&gt; "209 Werner", "150.5 Snyder", "209 Werner", "109 Mar…
## $ pollinator_father &lt;chr&gt; "Self", NA, "103 Mackinnon", "209 Werner '12", "open…
## $ ott               &lt;chr&gt; "184.0", "194.0", "177.0", "194.0", "0.0", "190.0", …
## $ est_weight        &lt;chr&gt; "129.00", "151.00", "115.00", "151.00", "0.00", "141…
## $ pct_chart         &lt;chr&gt; "20.0", "-3.0", "26.0", "-7.0", "0.0", "-1.0", "-4.0…
## $ variety           &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …
```

The target and many other numeric values are still categorical.

---

### Recoding variables


```r
pumpkins &lt;- pumpkins %&gt;% 
  mutate(across(c(place, weight_lbs, ott, est_weight, pct_chart),
                as.numeric))

glimpse(pumpkins)
```

```
## Rows: 28,065
## Columns: 14
## $ id                &lt;chr&gt; "2013-F", "2013-F", "2013-F", "2013-F", "2013-F", "2…
## $ place             &lt;dbl&gt; 1, 2, 3, 4, 5, 5, 7, 8, 9, 10, 11, 12, NA, 13, 14, 1…
## $ weight_lbs        &lt;dbl&gt; 154.5, 146.5, 145.0, 140.8, 139.0, 139.0, 136.5, 136…
## $ grower_name       &lt;chr&gt; "Ellenbecker, Todd &amp; Sequoia", "Razo, Steve", "Ellen…
## $ city              &lt;chr&gt; "Gleason", "New Middletown", "Glenson", "Combined Lo…
## $ state_prov        &lt;chr&gt; "Wisconsin", "Ohio", "Wisconsin", "Wisconsin", "Wisc…
## $ country           &lt;chr&gt; "United States", "United States", "United States", "…
## $ gpc_site          &lt;chr&gt; "Nekoosa Giant Pumpkin Fest", "Ohio Valley Giant Pum…
## $ seed_mother       &lt;chr&gt; "209 Werner", "150.5 Snyder", "209 Werner", "109 Mar…
## $ pollinator_father &lt;chr&gt; "Self", NA, "103 Mackinnon", "209 Werner '12", "open…
## $ ott               &lt;dbl&gt; 184, 194, 177, 194, 0, 190, 190, 182, 0, 0, 0, 177, …
## $ est_weight        &lt;dbl&gt; 129, 151, 115, 151, 0, 141, 142, 124, 0, 0, 0, 115, …
## $ pct_chart         &lt;dbl&gt; 20, -3, 26, -7, 0, -1, -4, 10, 0, 0, 0, 14, 4, 8, 14…
## $ variety           &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …
```

---

### id


```r
pumpkins %&gt;% 
* separate(id, sep = "-", into = c("year", "type")) %&gt;%
  count(type)
```

```
## # A tibble: 6 × 2
##   type      n
##   &lt;chr&gt; &lt;int&gt;
## 1 F      2756
## 2 L      1965
## 3 P     15965
## 4 S      1686
## 5 T      3166
## 6 W      2527
```

The documentation on GitHub states:

&gt; Types: F = "Field Pumpkin", P = "Giant Pumpkin", S = "Giant Squash", W = "Giant Watermelon", L = "Long Gourd" (length in inches, not weight in pounds), T = Tomato

---

### id


```r
pumpkins &lt;- pumpkins %&gt;% 
  separate(id, sep = "-", into = c("year", "type")) %&gt;% 
* mutate(type = case_when(
*   type == "F" ~ "Field Pumpkin",
*   type == "P" ~ "Giant Pumpkin",
*   type == "S" ~ "Giant Squash",
*   type == "W" ~ "Giant Watermelon",
*   type == "L" ~ "Long Gourd",
*   type == "T" ~ "Tomato"
* ))
```

---

### id


```r
pumpkins %&gt;% 
  count(type, sort = T)
```

```
## # A tibble: 6 × 2
##   type                 n
##   &lt;chr&gt;            &lt;int&gt;
## 1 Giant Pumpkin    15965
## 2 Tomato            3166
## 3 Field Pumpkin     2756
## 4 Giant Watermelon  2527
## 5 Long Gourd        1965
## 6 Giant Squash      1686
```

---

### id

For the purpose of this session, let's focus on predicting giant pumpkins' weights.


```r
pumpkins &lt;- pumpkins %&gt;% 
  filter(type %in% c("Giant Pumpkin"))
```


```r
pumpkins %&gt;% 
  count(type, sort = T)
```

```
## # A tibble: 1 × 2
##   type              n
##   &lt;chr&gt;         &lt;int&gt;
## 1 Giant Pumpkin 15965
```

---

### grower_name


```r
pumpkins %&gt;% 
  count(grower_name, sort = T)
```

```
## # A tibble: 6,508 × 2
##    grower_name              n
##    &lt;chr&gt;                &lt;int&gt;
##  1 Platte, Joe             47
##  2 Sherwood, Jim           42
##  3 Gansert, Norman         41
##  4 Wolf, Andy              41
##  5 Miller, Gary            38
##  6 Karkos, Udo             34
##  7 Melka, Friedrich        34
##  8 Werner, Quinn           33
##  9 Tobeck, Cindy           32
## 10 Stelts, Dave &amp; Carol    31
## # … with 6,498 more rows
```

Some recurring names, less frequent should be lumped together.

---

### city


```r
pumpkins %&gt;% 
  count(city, sort = T)
```

```
## # A tibble: 2,737 × 2
##    city            n
##    &lt;chr&gt;       &lt;int&gt;
##  1 &lt;NA&gt;         1569
##  2 Napa          152
##  3 Barnesville    93
##  4 Kasterlee      90
##  5 Paredes        73
##  6 Gentilly       68
##  7 Olympia        65
##  8 Auburn         64
##  9 Johnston       62
## 10 Kaukauna       60
## # … with 2,727 more rows
```

Same again.

---

### state_prov


```r
pumpkins %&gt;% 
  count(state_prov, sort = T)
```

```
## # A tibble: 134 × 2
##    state_prov       n
##    &lt;chr&gt;        &lt;int&gt;
##  1 Other         1549
##  2 Wisconsin     1031
##  3 California     991
##  4 Ontario        836
##  5 Ohio           713
##  6 Washington     712
##  7 Michigan       633
##  8 Pennsylvania   540
##  9 New York       505
## 10 Oregon         464
## # … with 124 more rows
```

Again.

---

### country


```r
pumpkins %&gt;% 
  count(country, sort = T)
```

```
## # A tibble: 30 × 2
##    country            n
##    &lt;chr&gt;          &lt;int&gt;
##  1 United States   9902
##  2 Canada          2163
##  3 Germany         1144
##  4 Italy            512
##  5 Austria          390
##  6 Japan            333
##  7 Belgium          291
##  8 United Kingdom   179
##  9 Spain            173
## 10 Slovenia         158
## # … with 20 more rows
```

Not that bad this time, likely fewer are enough.

---

### gpc_site


```r
pumpkins %&gt;% 
  count(gpc_site, sort = T)
```

```
## # A tibble: 173 × 2
##    gpc_site                                         n
##    &lt;chr&gt;                                        &lt;int&gt;
##  1 Wiegemeisterschaft Berlin/Brandenburg          453
##  2 Ohio Valley Giant Pumpkin Growers Weigh-off    376
##  3 Elk Grove Giant Pumpkin Festival               359
##  4 Nippon Ichi Dodekabocha Taikai                 333
##  5 Baumans Farm Giant Pumpkin Weigh-off           307
##  6 Stillwater Harvestfest                         298
##  7 Austrian Weigh-off                             285
##  8 Central Great Lakes Weigh-off                  271
##  9 Safeway World Championship Pumpkin Weigh-Off   270
## 10 Nekoosa Giant Pumpkin Fest                     263
## # … with 163 more rows
```

Again.

---

### seed_mother


```r
pumpkins %&gt;% 
  count(seed_mother, sort = T)
```

```
## # A tibble: 6,009 × 2
##    seed_mother       n
##    &lt;chr&gt;         &lt;int&gt;
##  1 &lt;NA&gt;           4424
##  2 unknown         169
##  3 Unknown         145
##  4 2145 McMullen   122
##  5 2009 Wallace    104
##  6 1985 Miller      89
##  7 1911 Urena       72
##  8 2363 Holland     61
##  9 2008 Neptune     60
## 10 1495 Stelts      52
## # … with 5,999 more rows
```

Way too many levels, also likely not useful if seeds cannot be used in the future.

---

### pollinator_father


```r
pumpkins %&gt;% 
  count(pollinator_father, sort = T)
```

```
## # A tibble: 3,465 × 2
##    pollinator_father     n
##    &lt;chr&gt;             &lt;int&gt;
##  1 &lt;NA&gt;               5160
##  2 self               1127
##  3 Self               1101
##  4 open                773
##  5 Open                665
##  6 2009 Wallace        143
##  7 2145 McMullen       124
##  8 unknown              82
##  9 Unknown              77
## 10 1985 Miller          68
## # … with 3,455 more rows
```

Again, likely not useful.

---

### ott (over-the-top inches)

![](Intro-to-Tidymodels_files/figure-html/unnamed-chunk-24-1.png)&lt;!-- --&gt;

Zeros? Likely the same as missing values, only not encoded as `NA`.

---

### ott (over-the-top inches)

Also, let's make that metric.


```r
pumpkins &lt;- pumpkins %&gt;% 
  mutate(ott = ott*2.54)
```

.center[
&lt;img src="GraphicsSlides/download.png" width="40%" /&gt;
]

---

### est_weight

![](Intro-to-Tidymodels_files/figure-html/unnamed-chunk-27-1.png)&lt;!-- --&gt;

Zeros? Same as with `ott`, likely need to drop them.

---

### est_weight

Make that metric as well.


```r
pumpkins &lt;- pumpkins %&gt;% 
  mutate(est_weight = est_weight/2.205)
```

The target as well:


```r
pumpkins &lt;- pumpkins %&gt;% 
  mutate(weight_lbs = weight_lbs/2.205) %&gt;% 
  rename(weight_kg = weight_lbs)
```

---

### weight_kg (Target)

![](Intro-to-Tidymodels_files/figure-html/unnamed-chunk-30-1.png)&lt;!-- --&gt;

---

### variety


```r
pumpkins %&gt;% 
  count(variety, sort = T)
```

```
## # A tibble: 1 × 2
##   variety     n
##   &lt;chr&gt;   &lt;int&gt;
## 1 &lt;NA&gt;    15965
```

It's clear what to do with this one.

---

### Looking for missing values


```r
*colMeans(is.na(pumpkins)) %&gt;%
  tidy() %&gt;%
  arrange(x) %&gt;%
  rename(pct = x) %&gt;%
  filter(pct &gt; 0) %&gt;%
  arrange(-pct)
```

```
## # A tibble: 9 × 2
##   names                  pct
##   &lt;chr&gt;                &lt;dbl&gt;
## 1 variety           1       
## 2 pollinator_father 0.323   
## 3 weight_kg         0.315   
## 4 est_weight        0.304   
## 5 seed_mother       0.277   
## 6 city              0.0983  
## 7 place             0.0857  
## 8 ott               0.000564
## 9 pct_chart         0.000564
```

---

### Dealing with `NA` and zeros


```r
pumpkins &lt;- pumpkins %&gt;% 
  select(-c(variety, pollinator_father, seed_mother, pct_chart)) %&gt;% 
  filter(ott &gt; 0,
         weight_kg &gt; 0)
```

---

### Dealing with `NA` and zeros


```r
colMeans(is.na(pumpkins))
```

```
##        year        type       place   weight_kg grower_name        city 
##  0.00000000  0.00000000  0.08823184  0.00000000  0.00000000  0.09574094 
##  state_prov     country    gpc_site         ott  est_weight 
##  0.00000000  0.00000000  0.00000000  0.00000000  0.03860143
```

There are still some `NA` values, but these are manageable with imputation.

---

### Converting all character variables to factors


```r
pumpkins &lt;- pumpkins %&gt;% 
  mutate(across(where(is.character), as.factor))

pumpkins %&gt;% head(5)
```

```
## # A tibble: 5 × 11
##   year  type       place weight_kg grower_name city  state_prov country gpc_site
##   &lt;fct&gt; &lt;fct&gt;      &lt;dbl&gt;     &lt;dbl&gt; &lt;fct&gt;       &lt;fct&gt; &lt;fct&gt;      &lt;fct&gt;   &lt;fct&gt;   
## 1 2013  Giant Pum…   356      453. Magarian, … Goff… New Hamps… United… Deerfie…
## 2 2013  Giant Pum…   356      453. Leland, Ne… Canby Oregon     United… Baumans…
## 3 2013  Giant Pum…   358      453. Pappas, Ed  Mars… Massachus… United… Deerfie…
## 4 2013  Giant Pum…   359      453. Northrup, … Suss… New Bruns… Canada  Journee…
## 5 2013  Giant Pum…   359      453. Schultz, C… Deco… Iowa       United… Ryan No…
## # … with 2 more variables: ott &lt;dbl&gt;, est_weight &lt;dbl&gt;
```

---

### Let's get modelling!

&lt;br&gt;
&lt;br&gt;

.center[
&lt;img src="GraphicsSlides/get in loser.png" width="60%" /&gt;
]

---

### Creating training and holdout splits


```r
dt_split &lt;- initial_split(pumpkins, strata = weight_kg)

dt_split
```

```
## &lt;Training/Testing/Total&gt;
## &lt;6390/2133/8523&gt;
```

---

### Creating training and holdout splits


```r
dt_train &lt;- training(dt_split)
dt_test &lt;- testing(dt_split)

dim(dt_train)
```

```
## [1] 6390   11
```

```r
dim(dt_test)
```

```
## [1] 2133   11
```

```r
dt_split
```

```
## &lt;Training/Testing/Total&gt;
## &lt;6390/2133/8523&gt;
```

---

### Cross-Validation for stable computation of model metrics


```r
folds &lt;- vfold_cv(dt_train, v = 5, strata = weight_kg)

folds
```

```
## #  5-fold cross-validation using stratification 
## # A tibble: 5 × 2
##   splits              id   
##   &lt;list&gt;              &lt;chr&gt;
## 1 &lt;split [5110/1280]&gt; Fold1
## 2 &lt;split [5111/1279]&gt; Fold2
## 3 &lt;split [5112/1278]&gt; Fold3
## 4 &lt;split [5113/1277]&gt; Fold4
## 5 &lt;split [5114/1276]&gt; Fold5
```

When tuning hyperparameters, these folds can be passed into the tuning function.

---

### Preprocessing with `recipes`

The recipe works similarly like the well known `lm(y ~ x)` function. You can add some variables...


```r
xg_rec &lt;- recipe(weight_kg ~ ott + est_weight + country,
                 data = dt_train)

xg_rec
```

```
## Recipe
## 
## Inputs:
## 
##       role #variables
##    outcome          1
##  predictor          3
```

---

### Preprocessing with `recipes`

The recipe works similarly like the well known `lm(y ~ x)` function. You can add some variables...

...or all variables.


```r
xg_rec &lt;- recipe(weight_kg ~ ., 
                 data = dt_train)

xg_rec
```

```
## Recipe
## 
## Inputs:
## 
##       role #variables
##    outcome          1
##  predictor         10
```

---

### Let's see what we still need to do


```r
glimpse(pumpkins)
```

```
## Rows: 8,523
## Columns: 11
## $ year        &lt;fct&gt; 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013…
## $ type        &lt;fct&gt; Giant Pumpkin, Giant Pumpkin, Giant Pumpkin, Giant Pumpkin…
## $ place       &lt;dbl&gt; 356, 356, 358, 359, 359, 361, 362, 363, 363, 366, 366, 370…
## $ weight_kg   &lt;dbl&gt; 453.2880, 453.2880, 453.0612, 452.8345, 452.8345, 452.6077…
## $ grower_name &lt;fct&gt; "Magarian, Marc", "Leland, Neal", "Pappas, Ed", "Northrup,…
## $ city        &lt;fct&gt; "Goffstown", "Canby", "Marshfield", "Sussex", "Decorah", "…
## $ state_prov  &lt;fct&gt; New Hampshire, Oregon, Massachusetts, New Brunswick, Iowa,…
## $ country     &lt;fct&gt; United States, United States, United States, Canada, Unite…
## $ gpc_site    &lt;fct&gt; Deerfield Fair, Baumans Farm Giant Pumpkin Weigh-off, Deer…
## $ ott         &lt;dbl&gt; 939.80, 904.24, 916.94, 883.92, 891.54, 916.94, 939.80, 87…
## $ est_weight  &lt;dbl&gt; NA, 450.7937, NA, 423.1293, 433.5601, NA, NA, 407.7098, NA…
```

- Factors: allow for new factor levels
- Remove: `type`
- Lump together: `grower_name`, `city`, `state_prov`, `country`, `gpc_site`
- Impute: variables with missing observations

---

### Preprocessing with `recipes`

Removing type:


```r
xg_rec &lt;- recipe(weight_kg ~ ., 
                 data = dt_train) %&gt;% 
* step_rm(type)

xg_rec %&gt;% prep() %&gt;% juice() %&gt;% head(5)
```

```
## # A tibble: 5 × 10
##   year  place grower_name     city  state_prov country gpc_site   ott est_weight
##   &lt;fct&gt; &lt;dbl&gt; &lt;fct&gt;           &lt;fct&gt; &lt;fct&gt;      &lt;fct&gt;   &lt;fct&gt;    &lt;dbl&gt;      &lt;dbl&gt;
## 1 2013   1175 Caleb, Dillion  Arva… Colorado   United… The Flo…  655.       175.
## 2 2013   1177 Gienger, Perry  &lt;NA&gt;  Minnesota  United… Stillwa…  615.       145.
## 3 2013   1179 Carlson, Ken    Danb… Connectic… United… Ridgefi…  610.       141.
## 4 2013   1180 Klug, Christian Berl… Other      Germany Wiegeme…  658.       178.
## 5 2013   1182 Mullen, Rich    Taun… Massachus… United… SNGPG F…  612.       143.
## # … with 1 more variable: weight_kg &lt;dbl&gt;
```

---

### Preprocessing with `recipes`

Imputing missing values with mode for categorical and median for numeric predictors:


```r
xg_rec &lt;- recipe(weight_kg ~ ., 
                 data = dt_train) %&gt;% 
  step_rm(type) %&gt;% 
* step_impute_median(all_numeric_predictors()) %&gt;%
* step_impute_mode(all_nominal_predictors())

colMeans(is.na(xg_rec %&gt;% prep() %&gt;% juice()))
```

```
##        year       place grower_name        city  state_prov     country 
##           0           0           0           0           0           0 
##    gpc_site         ott  est_weight   weight_kg 
##           0           0           0           0
```

---

### Preprocessing with `recipes`

.scroll-output[

Lumping factor levels together. Because the value "Other" is already a level in the factors, we need to recode the newly added "other" to "Other" to make it the same category.


```r
xg_rec &lt;- recipe(weight_kg ~ ., 
                 data = dt_train) %&gt;% 
  step_rm(type) %&gt;% 
  step_impute_median(all_numeric_predictors()) %&gt;% 
  step_impute_mode(all_nominal_predictors()) %&gt;% 
* step_other(grower_name, city, state_prov,
*            country, gpc_site,
*            threshold = 0.01) %&gt;%
* step_mutate(across(c(grower_name, city, state_prov,
*                      country, gpc_site),
*            ~ forcats::fct_recode(., "Other" = "other")))

xg_rec %&gt;% prep() %&gt;% juice() %&gt;% head()
```

```
## # A tibble: 6 × 10
##   year  place grower_name city    state_prov   country gpc_site   ott est_weight
##   &lt;fct&gt; &lt;dbl&gt; &lt;fct&gt;       &lt;fct&gt;   &lt;fct&gt;        &lt;fct&gt;   &lt;fct&gt;    &lt;dbl&gt;      &lt;dbl&gt;
## 1 2013   1175 Other       Other   Colorado     United… Other     655.       175.
## 2 2013   1177 Other       Paredes Minnesota    United… Stillwa…  615.       145.
## 3 2013   1179 Other       Other   Connecticut  United… Other     610.       141.
## 4 2013   1180 Other       Other   Other        Germany Wiegeme…  658.       178.
## 5 2013   1182 Other       Other   Massachuset… United… SNGPG F…  612.       143.
## 6 2013   1185 Other       Paredes Wisconsin    United… Stillwa…  625.       152.
## # … with 1 more variable: weight_kg &lt;dbl&gt;
```
]

---

### Preprocessing with `recipes`

.scroll-output[

Let's normalize the numerical predictors as well to see undistorted variable importance:


```r
xg_rec &lt;- recipe(weight_kg ~ ., 
                 data = dt_train) %&gt;% 
  step_rm(type) %&gt;% 
  step_impute_median(all_numeric_predictors()) %&gt;% 
  step_impute_mode(all_nominal_predictors()) %&gt;% 
  step_other(grower_name, city, state_prov, 
             country, gpc_site,
             threshold = 0.01) %&gt;% 
  step_mutate(across(c(grower_name, city, state_prov, 
                       country, gpc_site),
             ~ forcats::fct_recode(., "Other" = "other"))) %&gt;% 
* step_normalize(all_numeric_predictors())

xg_rec %&gt;% prep() %&gt;% juice() %&gt;% head()
```

```
## # A tibble: 6 × 10
##   year  place grower_name city    state_prov  country gpc_site    ott est_weight
##   &lt;fct&gt; &lt;dbl&gt; &lt;fct&gt;       &lt;fct&gt;   &lt;fct&gt;       &lt;fct&gt;   &lt;fct&gt;     &lt;dbl&gt;      &lt;dbl&gt;
## 1 2013  0.467 Other       Other   Colorado    United… Other    -0.334     -0.559
## 2 2013  0.474 Other       Paredes Minnesota   United… Stillwa… -0.601     -0.822
## 3 2013  0.480 Other       Other   Connecticut United… Other    -0.634     -0.850
## 4 2013  0.483 Other       Other   Other       Germany Wiegeme… -0.317     -0.535
## 5 2013  0.490 Other       Other   Massachuse… United… SNGPG F… -0.617     -0.838
## 6 2013  0.499 Other       Paredes Wisconsin   United… Stillwa… -0.534     -0.759
## # … with 1 more variable: weight_kg &lt;dbl&gt;
```

]

---

### Preprocessing with `recipes`

Let's allow for novel factor levels in the new data and one-hot encode the categorical variables as well:


```r
xg_rec &lt;- recipe(weight_kg ~ ., 
                 data = dt_train) %&gt;% 
  step_rm(type) %&gt;% 
  step_impute_median(all_numeric_predictors()) %&gt;% 
  step_impute_mode(all_nominal_predictors()) %&gt;% 
  step_other(grower_name, city, state_prov, 
             country, gpc_site,
             threshold = 0.01) %&gt;% 
  step_mutate(across(c(grower_name, city, state_prov, 
                       country, gpc_site),
             ~ forcats::fct_recode(., "Other" = "other"))) %&gt;% 
  step_normalize(all_numeric_predictors()) %&gt;% 
* step_novel(all_nominal_predictors()) %&gt;%
* step_dummy(all_nominal_predictors(), one_hot = TRUE)
```

---

### Preprocessing with `recipes`

.scroll-output[

Prepping and baking will apply all recipe steps to the new data, i.e. the holdout used for evaluation at a later stage.


```r
xg_rec %&gt;% prep() %&gt;% bake(dt_train) %&gt;% head()
```

```
## # A tibble: 6 × 104
##   place    ott est_weight weight_kg year_X2013 year_X2014 year_X2015 year_X2016
##   &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;
## 1 0.467 -0.334     -0.559      146.          1          0          0          0
## 2 0.474 -0.601     -0.822      146.          1          0          0          0
## 3 0.480 -0.634     -0.850      145.          1          0          0          0
## 4 0.483 -0.317     -0.535      145.          1          0          0          0
## 5 0.490 -0.617     -0.838      143.          1          0          0          0
## 6 0.499 -0.534     -0.759      142.          1          0          0          0
## # … with 96 more variables: year_X2017 &lt;dbl&gt;, year_X2018 &lt;dbl&gt;,
## #   year_X2019 &lt;dbl&gt;, year_X2020 &lt;dbl&gt;, year_X2021 &lt;dbl&gt;, year_new &lt;dbl&gt;,
## #   grower_name_Karkos..Udo &lt;dbl&gt;, grower_name_Other &lt;dbl&gt;,
## #   grower_name_new &lt;dbl&gt;, city_Paredes &lt;dbl&gt;, city_Other &lt;dbl&gt;,
## #   city_new &lt;dbl&gt;, state_prov_Antwerp &lt;dbl&gt;, state_prov_Brandenburg &lt;dbl&gt;,
## #   state_prov_British.Columbia &lt;dbl&gt;, state_prov_California &lt;dbl&gt;,
## #   state_prov_Colorado &lt;dbl&gt;, state_prov_Connecticut &lt;dbl&gt;, …
```
]

---

### Preprocessing with `recipes`

That's the recipe done! The recipe allows to 

- prevent data leakage
- create stepwise data preprocessing that is easy to understand
- no manual column indexing, subsetting, and whatever shenanigans Python requires you to do

&lt;br&gt;

&lt;blockquote class="twitter-tweet"&gt;&lt;p lang="en" dir="ltr"&gt;Silly complaint: &amp;quot;this tool keeps you from thinking.&amp;quot; No one stops thinking when they use good tools. They think about more important things&lt;/p&gt;&amp;mdash; David Robinson (@drob) &lt;a href="https://twitter.com/drob/status/769161059743756289?ref_src=twsrc%5Etfw"&gt;August 26, 2016&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src="https://platform.twitter.com/widgets.js" charset="utf-8"&gt;&lt;/script&gt;

---

### Setting up the model

.scroll-output[

```r
xg_spec &lt;- 
  boost_tree(
    trees = 750,
    tree_depth = tune(),
    min_n = tune(),
    loss_reduction = tune(),
    sample_size = tune(),
    mtry = tune(),
    learn_rate = tune()
  ) %&gt;%
  set_engine("xgboost", importance = "impurity") %&gt;%
  set_mode("regression")

xg_spec
```

```
## Boosted Tree Model Specification (regression)
## 
## Main Arguments:
##   mtry = tune()
##   trees = 750
##   min_n = tune()
##   tree_depth = tune()
##   learn_rate = tune()
##   loss_reduction = tune()
##   sample_size = tune()
## 
## Engine-Specific Arguments:
##   importance = impurity
## 
## Computational engine: xgboost
```
]

---

### Setting up the workflow

.scroll-output[

```r
xg_wflow &lt;- 
  workflow() %&gt;% 
  add_recipe(xg_rec) %&gt;% 
  add_model(xg_spec)

xg_wflow
```

```
## ══ Workflow ════════════════════════════════════════════════════════════════════
## Preprocessor: Recipe
## Model: boost_tree()
## 
## ── Preprocessor ────────────────────────────────────────────────────────────────
## 8 Recipe Steps
## 
## • step_rm()
## • step_impute_median()
## • step_impute_mode()
## • step_other()
## • step_mutate()
## • step_normalize()
## • step_novel()
## • step_dummy()
## 
## ── Model ───────────────────────────────────────────────────────────────────────
## Boosted Tree Model Specification (regression)
## 
## Main Arguments:
##   mtry = tune()
##   trees = 750
##   min_n = tune()
##   tree_depth = tune()
##   learn_rate = tune()
##   loss_reduction = tune()
##   sample_size = tune()
## 
## Engine-Specific Arguments:
##   importance = impurity
## 
## Computational engine: xgboost
```
]

---

### Setting up a tuning grid

.scroll-output[

```r
xg_grid &lt;- 
  grid_latin_hypercube(
    tree_depth(),
    min_n(),
    loss_reduction(),
    sample_size = sample_prop(),
    finalize(mtry(), dt_train),
    learn_rate(),
    size = 10
  )

xg_grid
```

```
## # A tibble: 10 × 6
##    tree_depth min_n loss_reduction sample_size  mtry learn_rate
##         &lt;int&gt; &lt;int&gt;          &lt;dbl&gt;       &lt;dbl&gt; &lt;int&gt;      &lt;dbl&gt;
##  1          6    26       3.31e- 8       0.610     1   9.86e- 7
##  2          3    22       3.81e+ 0       0.313     5   1.14e- 9
##  3         11    14       1.98e- 5       0.414     7   5.76e- 8
##  4          7    35       8.54e- 9       0.924     8   2.29e-10
##  5         12    18       3.22e-10       0.645    10   6.88e- 9
##  6         15    30       1.06e- 1       0.223     5   5.14e- 4
##  7          9    12       9.25e- 4       0.529     3   1.23e- 2
##  8         11     5       1.79e+ 0       0.734     4   1.91e- 2
##  9          2    39       3.72e- 7       0.878     6   1.04e- 5
## 10          5     6       1.98e- 4       0.157     9   6.92e- 5
```
]

---

### Tuning the model

.scroll-output[

This is the most time-intensive part with large amounts of data, so we're gonna use parallelisation here (using more of your CPU's cores). Make sure to edit this code according to your needs.


```r
start_time = Sys.time()

unregister_dopar &lt;- function() {
  env &lt;- foreach:::.foreachGlobals
  rm(list=ls(name=env), pos=env)
}

cl &lt;- makePSOCKcluster(6)
registerDoParallel(cl)

xg_tune &lt;- tune_grid(
  object = xg_wflow,
  resamples = folds,
  grid = xg_grid,
  control = control_grid(save_pred = TRUE)
  )

stopCluster(cl)
unregister_dopar()

end_time = Sys.time()
end_time - start_time
```

```
## Time difference of 38.56063 secs
```
]
---

### Looking at tuning results

.scroll-output[

```r
xg_tune %&gt;% 
  show_best("rsq") %&gt;% 
  glimpse()
```

```
## Rows: 5
## Columns: 12
## $ mtry           &lt;int&gt; 7, 9, 4, 10, 8
## $ min_n          &lt;int&gt; 31, 22, 34, 37, 26
## $ tree_depth     &lt;int&gt; 9, 14, 10, 4, 13
## $ learn_rate     &lt;dbl&gt; 5.177051e-02, 4.432054e-03, 9.737528e-04, 1.116042e-06,…
## $ loss_reduction &lt;dbl&gt; 1.061313e-07, 1.139845e-03, 9.713352e-06, 1.102271e+00,…
## $ sample_size    &lt;dbl&gt; 0.1290659, 0.7020608, 0.7302964, 0.9702553, 0.2625481
## $ .metric        &lt;chr&gt; "rsq", "rsq", "rsq", "rsq", "rsq"
## $ .estimator     &lt;chr&gt; "standard", "standard", "standard", "standard", "standa…
## $ mean           &lt;dbl&gt; 0.9633104, 0.9612772, 0.8459010, 0.8451141, 0.8428289
## $ n              &lt;int&gt; 5, 5, 5, 5, 5
## $ std_err        &lt;dbl&gt; 0.003083245, 0.002462037, 0.002272525, 0.005828876, 0.0…
## $ .config        &lt;chr&gt; "Preprocessor1_Model02", "Preprocessor1_Model10", "Prep…
```
]

---

### Selecting the best model configuration

.scroll-output[

```r
xg_final_wflow &lt;- xg_wflow %&gt;% 
  finalize_workflow(select_best(xg_tune, metric = "rsq"))

xg_final_wflow
```

```
## ══ Workflow ════════════════════════════════════════════════════════════════════
## Preprocessor: Recipe
## Model: boost_tree()
## 
## ── Preprocessor ────────────────────────────────────────────────────────────────
## 8 Recipe Steps
## 
## • step_rm()
## • step_impute_median()
## • step_impute_mode()
## • step_other()
## • step_mutate()
## • step_normalize()
## • step_novel()
## • step_dummy()
## 
## ── Model ───────────────────────────────────────────────────────────────────────
## Boosted Tree Model Specification (regression)
## 
## Main Arguments:
##   mtry = 7
##   trees = 750
##   min_n = 31
##   tree_depth = 9
##   learn_rate = 0.0517705075057277
##   loss_reduction = 1.06131318931382e-07
##   sample_size = 0.129065915360115
## 
## Engine-Specific Arguments:
##   importance = impurity
## 
## Computational engine: xgboost
```
]

---

### Fitting the final model on the initial split (entire training data)


```r
xg_final_fit &lt;- xg_final_wflow %&gt;% 
  last_fit(dt_split)

xg_final_fit
```

```
## # Resampling results
## # Manual resampling 
## # A tibble: 1 × 6
##   splits              id               .metrics .notes   .predictions .workflow 
##   &lt;list&gt;              &lt;chr&gt;            &lt;list&gt;   &lt;list&gt;   &lt;list&gt;       &lt;list&gt;    
## 1 &lt;split [6390/2133]&gt; train/test split &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt;     &lt;workflow&gt;
```

Let's inspect what's in there.

---

### Inspecting our final fit


```r
xg_final_fit %&gt;% 
  collect_metrics()
```

```
## # A tibble: 2 × 4
##   .metric .estimator .estimate .config             
##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               
## 1 rmse    standard      21.9   Preprocessor1_Model1
## 2 rsq     standard       0.967 Preprocessor1_Model1
```

---

### Inspecting our final fit


```r
xg_final_fit %&gt;% 
  collect_predictions()
```

```
## # A tibble: 2,133 × 5
##    id               .pred  .row weight_kg .config             
##    &lt;chr&gt;            &lt;dbl&gt; &lt;int&gt;     &lt;dbl&gt; &lt;chr&gt;               
##  1 train/test split  419.     4      453. Preprocessor1_Model1
##  2 train/test split  431.     7      452. Preprocessor1_Model1
##  3 train/test split  431.     9      452. Preprocessor1_Model1
##  4 train/test split  419.    12      450. Preprocessor1_Model1
##  5 train/test split  398.    14      449. Preprocessor1_Model1
##  6 train/test split  436.    15      449. Preprocessor1_Model1
##  7 train/test split  413.    21      446. Preprocessor1_Model1
##  8 train/test split  436.    25      445. Preprocessor1_Model1
##  9 train/test split  416.    28      444. Preprocessor1_Model1
## 10 train/test split  429.    38      437. Preprocessor1_Model1
## # … with 2,123 more rows
```

With this, we can make a useful plot.

---

### Inspecting our final fit


```r
xg_final_fit %&gt;% 
  collect_predictions() %&gt;% 
  ggplot(aes(weight_kg, .pred)) +
  geom_point(alpha = 0.5, colour = "midnightblue") +
  geom_abline(lty = "dashed", colour = "grey50", size = 0.75) +
  coord_equal() +
  labs(title = "Predictions vs. Actuals of Holdout")
```

![](Intro-to-Tidymodels_files/figure-html/unnamed-chunk-58-1.png)&lt;!-- --&gt;

---

### Variable Importance Plot

.scroll-output[

```r
xg_final_fit %&gt;%
  extract_workflow() %&gt;% 
  extract_fit_parsnip() %&gt;% 
  vi() %&gt;%
  slice_max(order_by = Importance, n = 7) %&gt;% 
  ggplot(aes(Importance, reorder(Variable, Importance))) +
  geom_col(fill = "midnightblue", colour = "white") +
  labs(title = "Variable Importance",
       subtitle = "Only the seven most important predictors are shown.",
       y = "Predictor",
       x = "Relative Variable Importance") +
  theme_bw() +
  theme(plot.title = element_text(face = "bold", size = 12),
        plot.subtitle = element_text(face = "italic", colour = "grey50"))
```

![](Intro-to-Tidymodels_files/figure-html/unnamed-chunk-59-1.png)&lt;!-- --&gt;
]
---

### Making predictions on new data

.scroll-output[


```r
one_pumpkin &lt;- dt_test %&gt;% 
  select(-weight_kg) %&gt;% 
  sample_n(1)

one_pumpkin %&gt;% glimpse()
```

```
## Rows: 1
## Columns: 10
## $ year        &lt;fct&gt; 2016
## $ type        &lt;fct&gt; Giant Pumpkin
## $ place       &lt;dbl&gt; 931
## $ grower_name &lt;fct&gt; "Turmolli, Andrea"
## $ city        &lt;fct&gt; "Calcio"
## $ state_prov  &lt;fct&gt; Lombardy
## $ country     &lt;fct&gt; Italy
## $ gpc_site    &lt;fct&gt; Festa della zucca di sale
## $ ott         &lt;dbl&gt; 787.4
## $ est_weight  &lt;dbl&gt; 302.0408
```

]
---

### Making predictions on new data

Feeding new data (in this case from the holdout) into the model enables you to make predictions. All recipe steps are applied and the workflow equally executed.


```r
xg_final_fit %&gt;% 
  extract_workflow() %&gt;% 
  predict(one_pumpkin)
```

```
## # A tibble: 1 × 1
##   .pred
##   &lt;dbl&gt;
## 1  299.
```

---

### Making predictions on new data

.scroll-output[

If you want to keep the characteristics of the new observation you made a prediction on, use `augment()` instead of `predict()`.


```r
xg_final_fit %&gt;% 
  extract_workflow() %&gt;% 
  augment(one_pumpkin) %&gt;% 
  glimpse()
```

```
## Rows: 1
## Columns: 11
## $ year        &lt;fct&gt; 2016
## $ type        &lt;fct&gt; Giant Pumpkin
## $ place       &lt;dbl&gt; 931
## $ grower_name &lt;fct&gt; "Turmolli, Andrea"
## $ city        &lt;fct&gt; "Calcio"
## $ state_prov  &lt;fct&gt; Lombardy
## $ country     &lt;fct&gt; Italy
## $ gpc_site    &lt;fct&gt; Festa della zucca di sale
## $ ott         &lt;dbl&gt; 787.4
## $ est_weight  &lt;dbl&gt; 302.0408
## $ .pred       &lt;dbl&gt; 299.2589
```

]

---

### That's all!

Of course you can fit a plethora of different models. These are just slightly different, the `tidymodels` framework stays the same, that's the superpower!

For instance, here is the specification for an elastic net:


```r
en_spec &lt;- linear_reg(penalty = tune(),
                      mixture = tune()) %&gt;% 
  set_engine("glmnet")

en_wflow &lt;-
  workflow() %&gt;% 
  add_recipe(en_rec) %&gt;% 
  add_model(en_spec)

en_grid &lt;- 
  grid_latin_hypercube(
    penalty(),
    mixture(),
    size = 100
    )
```

---

# That's all!

We hope this tutorial was useful! Feel free to make use of the code and don't despair if you encounter errors, that's totally normal. For further questions, feel free to reach out to us. Make sure to stay updated on our socials and via our website where all resources and dates are also published.

&lt;br&gt;

.center[
&lt;img src="GraphicsSlides/Logo RUG hell.png" width="60%" /&gt;

**[Website](https://rusergroupstgallen.github.io/) | [Instagram](https://www.instagram.com/rusergroupstgallen/?hl=en) | [Twitter](https://twitter.com/rusergroupsg)**

]

---

class: center, middle, inverse

# Thank you for attending!
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
