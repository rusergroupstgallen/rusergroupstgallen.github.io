<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Web-Scraping-with-Selenium.knit</title>
    <meta charset="utf-8" />
    <script src="libs/header-attrs/header-attrs.js"></script>
    <link href="libs/panelset/panelset.css" rel="stylesheet" />
    <script src="libs/panelset/panelset.js"></script>
    <link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">


class: center, middle, hide-logo



&lt;style type="text/css"&gt;
pre {
background: #F8F8F8;
max-width: 100%;
overflow-x: scroll;
}
&lt;/style&gt;

&lt;style type="text/css"&gt;
.scroll-output {
height: 80%;
overflow-y: scroll;
}
&lt;/style&gt;





# Web Scraping with Selenium

## by

&lt;img src="GraphicsSlides/Logo RUG hell.png" width="50%" /&gt;

##### Author/Presenter: Ruben
##### Last updated: _2022-10-13 12:27:42_

---

## Goals for today's session

Obvious ones:
- Learn about commonly used approaches to web scraping
- Know how to scrape websites using Selenium with R

Less obvious ones:
- Learn how to go about scraping "complex" websites
- Get a more intuitive understanding of the make-up of websites

---
## The basic idea behind web scraping

If interesting data is available openly on websites, why not just take it?

&lt;br&gt;

.center[
&lt;img src="GraphicsSlides/free-real-estate.gif" width="50%" /&gt;
]

---

## The basic idea behind web scraping

Just a couple of possible roadblocks:
- It's spread across a lot of sites
- It's unstructured

And most importantly: why do something by hand when you can write code for hours to do it for you?

.center[
&lt;img src="GraphicsSlides/rick-and-morty-you-pass-butter.gif" width="40%" /&gt;
]

---

## Different approaches for webscraping

You might have heard of these:
- BeautifulSoup
- Requests
- Scrapy
- Selenium

As you might have guessed, today we're using Selenium!

.center[
&lt;img src="GraphicsSlides/scraping_packages.png" width="80%" /&gt;
]

---

## Why use Selenium?

.pull-left[
### BeautifulSoup and Requests
are mainly used to
- GET web pages and
- support you in the extraction of data from the DOM (you don't need to fully understand this right now)

--&gt; "static" web scraping
]

.pull-right[
### Selenium
"drives" a browser and can therefore be used to scrape more complex websites with
- buttons to press
- inputs to fill out
- errors and timeouts

--&gt; "dynamic" web scraping
]

---

## The setup

First we need to install some packages:

```r
library(RSelenium)
library(xml2)
```
--

And choose our desired browser to drive (I like Chrome):

.center[
&lt;img src="GraphicsSlides/chrome.jpg" width="50%" /&gt;
]

---

## Download chromedriver

Chromedriver is a development tool. You can download it here:
https://chromedriver.chromium.org/downloads

.pull-left[
On Windows put the file in&lt;br&gt;
`C:\Windows\`
]

.pull-right[
On MacOS put the file in&lt;br&gt;
`/usr/bin/` &lt;br&gt;
(you get there by pressing `cmd + G` and pasting the path above)
]

.center[
&lt;img src="GraphicsSlides/im_a_mac.jpg" width="60%" /&gt;
]

---

## Today's target: homegate.ch

.center[
&lt;img src="GraphicsSlides/screenshot_homegate.jpg" width="100%" /&gt;
]

---

## Some considerations before we start

.pull-left[
- Why not just click the "search" button to have all the listings
- We have to enter a region

-&gt; way too annoying to do manually
]


.pull-right[
&lt;img src="GraphicsSlides/screenshot_filters.jpg" width="100%" /&gt;
]

---

## Some considerations before we start

Having a look around the page reveals that we can nonetheless access all the listings:

.center[
&lt;img src="GraphicsSlides/screenshot_for_rent.jpg" width="80%" /&gt;
]

We can go by canton and make Selenium click all the buttons for us

---

## Let's fire up that robo-browser


```r
chromeDr &lt;- rsDriver(browser = "chrome", port = 4569L, chromever = "105.0.5195.52",
                     extraCapabilities = list(chromeOptions = list(args = c('--disable-gpu', '--window-size=1280,800'),
                                                                   prefs = list(
                                                                     "profile.default_content_settings.popups" = 0L,
                                                                     "download.prompt_for_download" = FALSE,
                                                                     "directory_upgrade" = TRUE
                                                                   ))))

remDr &lt;- chromeDr[["client"]]
```

The extra options are used ensure that:
- We don't run into graphics driver issues
- We suppress popups
- We have adequate permissions

---

## Opening a webpage

From here it's like regular web browsing - except controlled by your code


```r
remDr$navigate("https://www.homegate.ch/mieten/immobilien/land-schweiz")
```

Interacting with the filters and buttons is just as easy:


```r
e &lt;- remDr$findElement(value = '//*[@id="app"]/main/div/div/div[2]/div[1]/div/div[2]/div/div[1]/div[2]/a/span')
e$clickElement()
```

---

## How to find stuff on a webpage

We find elements (such as buttons and the data we want) via XPATHs (among others)

Like you've seen previously:&lt;br&gt;

```r
'//*[@id="app"]/main/div/div/div[2]/...'
```

.center[
&lt;img src="GraphicsSlides/what-the.gif" width="50%" /&gt;
]

---

## The DOM

Webpages are built in the hypertext markup language (HTML):&lt;br&gt;


```html
&lt;!DOCTYPE html&gt;
  &lt;html&gt;
  &lt;body&gt;
  &lt;h1&gt;My First Heading&lt;/h1&gt;
  &lt;p&gt;My first paragraph.&lt;/p&gt;
  &lt;/body&gt;
  &lt;/html&gt;
```

XPATHs are just a way to express the "path" of any element in this structure

--

In this case: to get the heading element:&lt;br&gt;

```r
'//body/h1'
```

---

## Extracting the actual data

Depending on the element, we want different attributes of the elements:
- text
- href (a link)
- value (with inputs)

or even metadata:
- whether the element exists
- how many of the same elements exist
- the child elements

---

## Example


```html
&lt;body&gt;
  &lt;div&gt;
  &lt;a href='https://example.com'&gt;Link 1&lt;/a&gt;
  &lt;a href='https://example.com'&gt;Link 2&lt;/a&gt;
  &lt;a href='https://example.com'&gt;Link 3&lt;/a&gt;
  &lt;/div&gt;
  &lt;/body&gt;
```
  
--
  

```r
'//body/div/a[2]'
```

gives us:
.pull-left[
- text: &lt;mark&gt;"Link 2"&lt;/mark&gt;
- href: &lt;mark&gt;"https://example.com"&lt;/mark&gt;
- value: &lt;mark&gt;None&lt;/mark&gt;
]

.pull-right[
- element exists: &lt;mark&gt;yes&lt;/mark&gt;
- how many of the same elements exist: &lt;mark&gt;3&lt;/mark&gt;
- the child elements: &lt;mark&gt;None&lt;/mark&gt;
]

---

## Supertrick: Getting XPATHS easily

In your browser, open the developer console:&lt;br&gt;
`F12` or `cmd + opt + i`

Find the element with the picker tool (top left) and copy its XPATH

.center[
&lt;img src="GraphicsSlides/screenshot-xpath.jpg" width="50%" /&gt;
]

---

### Task 1: Get the text of the pink button on homegate

**Tip:** Start by finding the element and then extract its *text* attribute as follows:


```r
remDr$findElement(value = '//some XPATH')$getElementText()
```

.center[
&lt;img src="GraphicsSlides/programmer.png" width="50%" /&gt;
]

---
### Solution



```r
remDr$findElement(value = '//*[@id="app"]/main/div/div[2]/div/div/div[5]/button')$getElementText()
```


```r
[[1]]
[1] "Suchen"
```

---

## Finding multiple elements

Often it is useful to find multiple elements at once.

.center[
&lt;img src="GraphicsSlides/screenshot_for_rent.jpg" width="50%" /&gt;
]

Here we could extract the links to all cantons and save them to go through later.


```r
e &lt;- remDr$findElements(value = "//*/div[contains(@class, 'GeoDrillDownSRPLink')]/a")

canton_links &lt;- unlist(lapply(e, function(x){x$getElementAttribute("href")}))[2:27]
```

---

## New concept: element attribute

HTML elements carry more data than just a text. These can be useful for &lt;b&gt; finding &lt;/b&gt; elements as well as &lt;b&gt; extracting &lt;/b&gt; additional data.

- Example of a `&lt;div&gt;` tag with a class:


```html
&lt;div class="my_class_name"&gt; Text &lt;/div&gt;
```

-&gt; We can use the class to &lt;b&gt; find &lt;/b&gt; this `&lt;div&gt;` element.

- Example of an `&lt;a&gt;` tag with an href (a link):


```html
&lt;a href="https://example.com"&gt; Link to example.com &lt;/a&gt;
```

-&gt; We might want to &lt;b&gt; extract &lt;/b&gt; this link

---

## Homegate does not like to be scraped

With the specific example of Homegate, we have a problem:

&lt;b&gt; They randomize their classes, so we cannot easily grab them &lt;/b&gt;

&lt;b&gt; BUT: &lt;/b&gt; we have a solution:

Instead of searching for a specific class (with the randomized part in it), we just search for the constant part:


```html
*&lt;div class="GeoDrillDownSRPLink_srpLink_2Zztq col-md-5"&gt; Text &lt;/div&gt;
```

We can do that by specifying `contains(@class, 'my_class_name')` in square brackets:


```r
e &lt;- remDr$findElements(value = "//*/div[contains(@class, 'GeoDrillDownSRPLink')]/a")
```

---

## Other attributes

The class attribute is generally the most useful for finding elements, however you might need to use others:
- id
- css styles
- title
- value
- etc.

You can use the same syntax:
- if looking for the exact attribute:


```r
e &lt;- remDr$findElements(value = "//*/div[@id='full_id_name']/a")
```

- if looking for partial attribute name:


```r
e &lt;- remDr$findElements(value = "//*/div[contains(@id, 'partial_id_name')]/a")
```

---

## Let's get into the main scraping

Now we have all the links of the Cantons, let's look at the actual listings.

First, navigate to the first Canton's page:


```r
e &lt;- remDr$navigate(canton_links[1])
```

.center[
&lt;img src="GraphicsSlides/screenshot_listing_1.png" width="100%" /&gt;
]

---

## What to scrape

Thinking about potential analyses we might want to conduct, interesting values to scrape could be:
- price
- size of the appartment
- number of rooms
- location
- description (maybe we can extract important keywords)

Less obvious but useful: &lt;b&gt; the link &lt;/b&gt; of the detailed listing. At a later time we might want to extract more data from the listing and saving the link will make this much easier.

---

### Task 2: Find the XPATH of all elements containing the price

**Tip:** You might need to find the class of the parent elements

&lt;br&gt;
&lt;br&gt;
&lt;br&gt;

.center[
&lt;img src="GraphicsSlides/programmer.png" width="50%" /&gt;
]

---

### Solution

The price is in a `&lt;span&gt;` element without a class. However, the parent of this `&lt;span&gt;` (which is another `&lt;span&gt;`) has the convenient `class='ListItemPrice_price_1o0i3'`.

Again, Homegate includes a random part '1o0i3' (this might be different for you), but we can just search for the first part of the class name:


```r
e &lt;- remDr$findElements(value = "//*/span[contains(@class, 'ListItemPrice')]/span[2]")
```

So let's see what we have scraped:


```r
canton_links &lt;- unlist(lapply(e, function(x){x$getElementText()}))
```













---

# So let's recap

We wanted:

- Title page
- Table of contents
- Table of figures
- Page numbering
- Citations
- References
- ...

And most importantly: No more manual copying and pasting.

---

# That's it for today!

**Some finishing words**

For further questions, feel free to reach out to us. Make sure to stay updated on our socials and via our website where all resources and dates are also published.

&lt;br&gt;

.center[
&lt;img src="GraphicsSlides/Logo RUG hell.png" width="60%" /&gt;

**[Website](https://rusergroup-sg.ch/) | [Instagram](https://www.instagram.com/rusergroupstgallen/?hl=en) | [Twitter](https://twitter.com/rusergroupsg)**

]

---

class: middle, inverse, hide-logo

# Thank you for attending!

<em style="color:#404040">The material provided in this presentation including any information, tools, features, content and any images incorporated in the presentation, is solely for your lawful, personal, private use. You may not modify, republish, or post anything you obtain from this presentation, including anything you download from our website, unless you first obtain our written consent. You may not engage in systematic retrieval of data or other content from this website. We request that you not create any kind of hyperlink from any other site to ours unless you first obtain our written permission.</em>
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>
<style>
.logo {
  background-image: url(GraphicsSlides/Logo\ RUG\ hell.png);
  background-size: contain;
  background-repeat: no-repeat;
  position: absolute;
  bottom: -85px;
  left: 1em;
  width: 80px;
  height: 128px;
  z-index: 0;
}
</style>

<script>
document
  .querySelectorAll(
    '.remark-slide-content' +
    ':not(.title-slide)' +
    // add additional classes to exclude here, e.g.
    // ':not(.inverse)' +
    ':not(.hide-logo)'
  )
  .forEach(el => {
    el.innerHTML += '<div class="logo"></div>';
  });
</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
